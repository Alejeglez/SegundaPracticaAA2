{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segunda Práctica Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alejandro Jesús González Santana y Joaquín Ibáñez Peñalva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from functions_metrics import PSNR, SSIM, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SuperResolutionAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperResolutionAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        decoded = F.interpolate(decoded, size=(28, 28), mode='bilinear', align_corners=False)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.0423\n",
      "Epoch:2, Loss:0.0254\n",
      "Epoch:3, Loss:0.0248\n",
      "Epoch:4, Loss:0.0224\n",
      "Epoch:5, Loss:0.0168\n",
      "Epoch:6, Loss:0.0176\n",
      "Epoch:7, Loss:0.0176\n",
      "Epoch:8, Loss:0.0172\n",
      "Epoch:9, Loss:0.0151\n",
      "Epoch:10, Loss:0.0159\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_data, batch_size=64, shuffle=True)\n",
    "\n",
    "mnist_data_valid = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "data_loader_valid = torch.utils.data.DataLoader(dataset=mnist_data_valid, batch_size=64, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SuperResolutionAutoencoder().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (images, _) in enumerate(data_loader):\n",
    "        lr_images = F.interpolate(images, size=(14, 14), mode='area').to(device)\n",
    "        hr_images = images.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(lr_images)\n",
    "        loss = criterion(outputs, hr_images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalución de la red con nuevos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 66.9681, MAE: 0.0374\n",
      "PSNR: 66.8861, MAE: 0.0377\n",
      "PSNR: 66.3049, MAE: 0.0392\n",
      "PSNR: 66.2450, MAE: 0.0409\n",
      "PSNR: 66.9407, MAE: 0.0366\n",
      "PSNR: 66.5051, MAE: 0.0398\n",
      "PSNR: 66.7929, MAE: 0.0366\n",
      "PSNR: 66.8794, MAE: 0.0378\n",
      "PSNR: 66.4388, MAE: 0.0395\n",
      "PSNR: 66.8188, MAE: 0.0379\n",
      "PSNR: 66.4182, MAE: 0.0392\n",
      "PSNR: 66.7939, MAE: 0.0380\n",
      "PSNR: 66.4985, MAE: 0.0387\n",
      "PSNR: 66.1583, MAE: 0.0395\n",
      "PSNR: 66.5760, MAE: 0.0396\n",
      "PSNR: 66.2750, MAE: 0.0401\n",
      "PSNR: 66.4602, MAE: 0.0398\n",
      "PSNR: 66.3598, MAE: 0.0407\n",
      "PSNR: 65.8738, MAE: 0.0419\n",
      "PSNR: 66.5380, MAE: 0.0390\n",
      "PSNR: 66.7513, MAE: 0.0373\n",
      "PSNR: 66.5875, MAE: 0.0375\n",
      "PSNR: 66.8016, MAE: 0.0376\n",
      "PSNR: 66.7099, MAE: 0.0378\n",
      "PSNR: 66.8944, MAE: 0.0374\n",
      "PSNR: 66.4522, MAE: 0.0397\n",
      "PSNR: 66.3457, MAE: 0.0401\n",
      "PSNR: 66.3160, MAE: 0.0401\n",
      "PSNR: 66.7414, MAE: 0.0383\n",
      "PSNR: 66.4790, MAE: 0.0387\n",
      "PSNR: 66.1746, MAE: 0.0412\n",
      "PSNR: 66.9767, MAE: 0.0361\n",
      "PSNR: 66.2705, MAE: 0.0407\n",
      "PSNR: 66.7783, MAE: 0.0370\n",
      "PSNR: 66.7637, MAE: 0.0370\n",
      "PSNR: 66.5671, MAE: 0.0385\n",
      "PSNR: 65.8097, MAE: 0.0425\n",
      "PSNR: 66.3594, MAE: 0.0399\n",
      "PSNR: 66.6887, MAE: 0.0380\n",
      "PSNR: 66.7332, MAE: 0.0368\n",
      "PSNR: 66.4195, MAE: 0.0399\n",
      "PSNR: 66.6464, MAE: 0.0390\n",
      "PSNR: 66.6339, MAE: 0.0391\n",
      "PSNR: 66.4333, MAE: 0.0403\n",
      "PSNR: 66.3874, MAE: 0.0400\n",
      "PSNR: 66.4222, MAE: 0.0405\n",
      "PSNR: 66.5456, MAE: 0.0384\n",
      "PSNR: 66.0375, MAE: 0.0412\n",
      "PSNR: 66.7708, MAE: 0.0377\n",
      "PSNR: 67.1605, MAE: 0.0362\n",
      "PSNR: 66.8163, MAE: 0.0379\n",
      "PSNR: 66.6409, MAE: 0.0379\n",
      "PSNR: 66.5235, MAE: 0.0392\n",
      "PSNR: 66.3234, MAE: 0.0409\n",
      "PSNR: 66.7228, MAE: 0.0385\n",
      "PSNR: 66.7597, MAE: 0.0378\n",
      "PSNR: 66.4527, MAE: 0.0384\n",
      "PSNR: 66.2580, MAE: 0.0399\n",
      "PSNR: 66.6103, MAE: 0.0391\n",
      "PSNR: 67.0017, MAE: 0.0370\n",
      "PSNR: 66.4912, MAE: 0.0397\n",
      "PSNR: 66.6382, MAE: 0.0383\n",
      "PSNR: 66.4726, MAE: 0.0391\n",
      "PSNR: 66.4142, MAE: 0.0394\n",
      "PSNR: 66.3425, MAE: 0.0407\n",
      "PSNR: 66.4759, MAE: 0.0398\n",
      "PSNR: 66.3800, MAE: 0.0395\n",
      "PSNR: 66.6133, MAE: 0.0387\n",
      "PSNR: 66.4678, MAE: 0.0396\n",
      "PSNR: 66.2813, MAE: 0.0409\n",
      "PSNR: 66.6571, MAE: 0.0385\n",
      "PSNR: 66.1589, MAE: 0.0417\n",
      "PSNR: 66.5359, MAE: 0.0393\n",
      "PSNR: 66.9303, MAE: 0.0371\n",
      "PSNR: 66.3653, MAE: 0.0385\n",
      "PSNR: 66.4888, MAE: 0.0386\n",
      "PSNR: 66.6105, MAE: 0.0393\n",
      "PSNR: 66.5915, MAE: 0.0385\n",
      "PSNR: 66.6381, MAE: 0.0366\n",
      "PSNR: 66.9074, MAE: 0.0367\n",
      "PSNR: 66.5150, MAE: 0.0387\n",
      "PSNR: 66.6649, MAE: 0.0388\n",
      "PSNR: 66.3672, MAE: 0.0397\n",
      "PSNR: 66.5267, MAE: 0.0383\n",
      "PSNR: 66.5404, MAE: 0.0384\n",
      "PSNR: 66.5145, MAE: 0.0393\n",
      "PSNR: 66.3198, MAE: 0.0399\n",
      "PSNR: 66.6889, MAE: 0.0389\n",
      "PSNR: 66.6316, MAE: 0.0384\n",
      "PSNR: 66.2777, MAE: 0.0407\n",
      "PSNR: 66.6365, MAE: 0.0380\n",
      "PSNR: 66.8777, MAE: 0.0373\n",
      "PSNR: 66.3728, MAE: 0.0400\n",
      "PSNR: 66.8237, MAE: 0.0371\n",
      "PSNR: 66.5046, MAE: 0.0397\n",
      "PSNR: 66.6709, MAE: 0.0381\n",
      "PSNR: 66.8505, MAE: 0.0375\n",
      "PSNR: 66.8181, MAE: 0.0381\n",
      "PSNR: 66.6727, MAE: 0.0379\n",
      "PSNR: 66.5128, MAE: 0.0396\n",
      "PSNR: 66.6273, MAE: 0.0385\n",
      "PSNR: 66.9502, MAE: 0.0364\n",
      "PSNR: 66.7407, MAE: 0.0376\n",
      "PSNR: 67.0946, MAE: 0.0368\n",
      "PSNR: 66.5225, MAE: 0.0391\n",
      "PSNR: 66.6366, MAE: 0.0381\n",
      "PSNR: 66.8323, MAE: 0.0372\n",
      "PSNR: 66.6178, MAE: 0.0390\n",
      "PSNR: 66.5500, MAE: 0.0398\n",
      "PSNR: 66.9827, MAE: 0.0358\n",
      "PSNR: 66.4787, MAE: 0.0398\n",
      "PSNR: 66.5119, MAE: 0.0402\n",
      "PSNR: 66.5690, MAE: 0.0393\n",
      "PSNR: 66.3408, MAE: 0.0411\n",
      "PSNR: 66.4262, MAE: 0.0402\n",
      "PSNR: 66.5983, MAE: 0.0386\n",
      "PSNR: 66.6664, MAE: 0.0388\n",
      "PSNR: 66.3887, MAE: 0.0391\n",
      "PSNR: 67.3115, MAE: 0.0351\n",
      "PSNR: 66.6229, MAE: 0.0390\n",
      "PSNR: 66.2911, MAE: 0.0400\n",
      "PSNR: 66.8064, MAE: 0.0379\n",
      "PSNR: 66.7580, MAE: 0.0383\n",
      "PSNR: 66.5362, MAE: 0.0388\n",
      "PSNR: 66.9519, MAE: 0.0365\n",
      "PSNR: 66.6810, MAE: 0.0380\n",
      "PSNR: 66.3615, MAE: 0.0393\n",
      "PSNR: 66.5721, MAE: 0.0390\n",
      "PSNR: 66.6436, MAE: 0.0385\n",
      "PSNR: 66.6891, MAE: 0.0376\n",
      "PSNR: 66.3940, MAE: 0.0403\n",
      "PSNR: 66.3486, MAE: 0.0400\n",
      "PSNR: 66.5020, MAE: 0.0389\n",
      "PSNR: 66.3925, MAE: 0.0401\n",
      "PSNR: 66.5413, MAE: 0.0396\n",
      "PSNR: 66.8490, MAE: 0.0373\n",
      "PSNR: 66.1840, MAE: 0.0412\n",
      "PSNR: 66.5187, MAE: 0.0379\n",
      "PSNR: 66.6047, MAE: 0.0383\n",
      "PSNR: 66.5716, MAE: 0.0390\n",
      "PSNR: 66.5936, MAE: 0.0382\n",
      "PSNR: 66.8036, MAE: 0.0381\n",
      "PSNR: 66.4640, MAE: 0.0396\n",
      "PSNR: 66.3116, MAE: 0.0416\n",
      "PSNR: 66.5691, MAE: 0.0394\n",
      "PSNR: 66.2660, MAE: 0.0397\n",
      "PSNR: 66.5311, MAE: 0.0391\n",
      "PSNR: 66.0341, MAE: 0.0424\n",
      "PSNR: 66.3705, MAE: 0.0399\n",
      "PSNR: 66.4291, MAE: 0.0385\n",
      "PSNR: 66.4390, MAE: 0.0394\n",
      "PSNR: 66.2782, MAE: 0.0411\n",
      "PSNR: 66.8023, MAE: 0.0374\n",
      "PSNR: 66.6142, MAE: 0.0392\n",
      "PSNR: 66.4864, MAE: 0.0388\n",
      "PSNR: 66.1922, MAE: 0.0409\n",
      "PSNR: 67.1412, MAE: 0.0370\n",
      "Average MSE: 0.0144\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_mse = 0\n",
    "num_samples = 0\n",
    "for (img, labels) in data_loader_valid:\n",
    "    img = img.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reduced_img = F.interpolate(img, size=(14, 14), mode='area')\n",
    "        recon = model(reduced_img)\n",
    "        recon = F.interpolate(recon, size=(28, 28), mode='bicubic', align_corners=False)\n",
    "        mse = criterion(recon, img)\n",
    "        total_mse += mse.item() * img.size(0)\n",
    "        num_samples += img.size(0)\n",
    "        \n",
    "        psnr_value = PSNR(recon, img)\n",
    "        recon_np = recon.cpu().numpy()\n",
    "        img_np = img.cpu().numpy()\n",
    "        mae_value = mae(recon, img)\n",
    "\n",
    "        print(f'PSNR: {psnr_value:.4f}, MAE: {mae_value:.4f}')\n",
    "\n",
    "average_mse = total_mse / num_samples\n",
    "\n",
    "\n",
    "print(f'Average MSE: {average_mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medidas para un conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(data_loader_valid)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    reduced_img = F.interpolate(images, size=(14, 14), mode='area')\n",
    "    reconstructions = model(reduced_img)\n",
    "\n",
    "images_np = images.cpu().numpy()\n",
    "reduced_images_np = reduced_img.cpu().numpy()\n",
    "reconstructions_fixed = F.interpolate(reconstructions, size=(28, 28), mode='bicubic', align_corners=False)\n",
    "reconstructions_fixed_np = reconstructions_fixed.cpu().numpy()\n",
    "reconstructions_np = reconstructions.cpu().numpy()\n",
    "\n",
    "\n",
    "num_images = 10\n",
    "\n",
    "fig, axes = plt.subplots(num_images, 5, figsize=(16, 2*num_images))\n",
    "\n",
    "for i in range(num_images):\n",
    "    original_gray = images_np[i].reshape(28, 28)\n",
    "    reconstructed_gray = reconstructions_fixed_np[i].reshape(28, 28)\n",
    "    reduced_img_gray = reduced_images_np[i].reshape(14, 14)\n",
    "    ssim_index = SSIM(original_gray, reconstructed_gray)\n",
    "\n",
    "    axes[i, 0].hist(original_gray.flatten(), bins=50, color='blue', alpha=0.7, label='Original')\n",
    "    axes[i, 0].set_title('Histograma de Píxeles - Original')\n",
    "    axes[i, 0].set_xlabel('Valor de Píxel')\n",
    "    axes[i, 0].set_ylabel('Frecuencia')\n",
    "    axes[i, 0].legend()\n",
    "\n",
    "    axes[i, 1].hist(reconstructed_gray.flatten(), bins=50, color='orange', alpha=0.7, label='Reconstruido')\n",
    "    axes[i, 1].set_title('Histograma de Píxeles - Reconstruido')\n",
    "    axes[i, 1].set_xlabel('Valor de Píxel')\n",
    "    axes[i, 1].set_ylabel('Frecuencia')\n",
    "    axes[i, 1].legend()\n",
    "\n",
    "    axes[i, 2].imshow(original_gray, cmap='gray')\n",
    "    axes[i, 2].set_title('Imagen Original')\n",
    "\n",
    "    axes[i, 3].imshow(reconstructed_gray, cmap='gray')\n",
    "    axes[i, 3].set_title(f'Imagen Reconstruida - SSIM: {ssim_index:.4f}')\n",
    "\n",
    "    axes[i, 4].imshow(reduced_img_gray, cmap='gray')\n",
    "    axes[i, 4].set_title('Imagen de Baja Resolución')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
